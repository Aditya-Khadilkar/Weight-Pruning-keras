{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adagrad.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3tad-NiDsII4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wc8Z10I7sOVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Activation, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from keras.utils import *\n",
        "def FModel(input_shape):\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "    X = Dense(1000, kernel_initializer='normal', activation='relu')(X_input)\n",
        "    X = Dense(1000, activation = 'relu', name = 'fc2')(X)\n",
        "    X = Dense(500, activation = 'relu', name = 'fc3')(X)\n",
        "    X = Dense(200, activation = 'relu', name = 'fc4')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(10, activation = 'sigmoid', name = 'fc5')(X)\n",
        "    model = Model(inputs = X_input, outputs = X, name = 'FModel')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWbVBCY-sTru",
        "colab_type": "code",
        "outputId": "6a9e807d-c0e8-4f49-c8f4-e63003067c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "DLModel = FModel((28,28))\n",
        "DLModel.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = [\"accuracy\"])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJOX3pJ4sWUc",
        "colab_type": "code",
        "outputId": "06d361e7-8cbc-42a8-e55b-9f0600f5e289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "y_trainf = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_testf = keras.utils.to_categorical(y_test, num_classes)\n",
        "xts = x_train.shape\n",
        "yts = y_train.shape\n",
        "print(\"x train shape is : \", xts)\n",
        "print(\"y train shape is : \", yts)\n",
        "DLModel.fit(x = x_train,y = y_trainf, epochs = 10, batch_size = 64)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x train shape is :  (60000, 28, 28)\n",
            "y train shape is :  (60000,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 18s 299us/step - loss: 1.6149 - acc: 0.8995\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 17s 282us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 1.6118 - acc: 0.9000\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 1.6118 - acc: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f829b26b278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "_oqVf5TvsaNo",
        "colab_type": "code",
        "outputId": "eed7c187-e4d8-4025-d5b5-9b06d4633c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "preds = DLModel.evaluate(x_test,y_testf)\n",
        "### END CODE HERE ###\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(round(preds[1]*100,3)) + \" %\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 136us/step\n",
            "\n",
            "Loss = 1.611809492111206\n",
            "Test Accuracy = 90.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LBgNaX0iv0FJ",
        "colab_type": "code",
        "outputId": "bdf619bf-3909-4272-ff96-b71ee16ecced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "w = DLModel.get_weights()\n",
        "\n",
        "def prunew(list1, p): #function to prune weights connections args: 2D numpy array of weight matrix of a single layer, percentage of pruning\n",
        "    a = len(list1)\n",
        "    N = a*(100-p)/100\n",
        "    N = int(round(N)) #N = no.of elements that should remain after pruning\n",
        "    final_list = [] \n",
        "    l2 = list1.flatten()\n",
        "    l3 = list1.flatten()\n",
        "  \n",
        "    for i in range(0, N):  #a for loop which will append final_list with N highest weights of the given matrix\n",
        "        max1 = 0\n",
        "        ind = 0\n",
        "          \n",
        "        for j in range(len(l2)):  \n",
        "            l2[j]\n",
        "            if abs(l2[j]) > abs(max1):\n",
        "              \n",
        "                max1 = l2[j];\n",
        "                ind = j;\n",
        "        l2 = np.delete(l2,ind);           \n",
        "        final_list.append(max1) \n",
        "    t = min(map(abs, final_list)) #t is the threshold ie. minimum absolute value of the weight which is allowed after pruning else prune.\n",
        "    for k in range(len(l3)):\n",
        "      if abs(l3[k]) < t:\n",
        "        l3[k] = 0; \n",
        "      else:\n",
        "        pass\n",
        "    return l3 #flat list1 but it is now pruned. we will reshape it in main \n",
        "\n",
        "#main\n",
        "we = []\n",
        "wo = []\n",
        "wep = []\n",
        "for i in range(len(w)):\n",
        "  if i%2==0:\n",
        "    we.append(w[i])\n",
        "  else:\n",
        "    wo.append(w[i]) #every alternate weight matrices are 2D and 1D arrays hence we = even, wo is odd\n",
        "\n",
        "for z in we:\n",
        "  if len(z)>100:\n",
        "    pr = prunew(z,99)\n",
        "    prr = np.reshape(pr,z.shape)\n",
        "    wep.append(prr) # we wont touch odd ones we only need to prune connections\n",
        "  else:\n",
        "    wep.append(z)\n",
        "wprunedfinal = []\n",
        "for i in range(5):\n",
        "  wprunedfinal.append(wep[i])\n",
        "  wprunedfinal.append(wo[i]) #append all the pruned and odd matrices to wprunedfinal ie. our new weight matrix\n",
        "\n",
        "  \n",
        "pmodel = DLModel\n",
        "pmodel.set_weights(wprunedfinal) # make a copy of the model and set new weight matrix to tha copy\n",
        "preds = pmodel.evaluate(x_test,y_testf) #evaluate loss and accuracy\n",
        "### END CODE HERE ###\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(round(preds[1]*100,3)) + \" %\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 138us/step\n",
            "\n",
            "Loss = 0.38914118766784667\n",
            "Test Accuracy = 90.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T75BXijDUtl6",
        "colab_type": "code",
        "outputId": "645dccc5-b58d-430c-c492-790a7c357ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        " pmodel.fit(x = x_train,y = y_trainf, epochs = 5, batch_size = 64) #THIS IS VERY SURPRIZING. RETRAINING A PRUNED MODEL JUMPS UP 10%"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 18s 293us/step - loss: 0.0711 - acc: 0.9766\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 18s 292us/step - loss: 0.0399 - acc: 0.9871\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 18s 293us/step - loss: 0.0362 - acc: 0.9883\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 18s 293us/step - loss: 0.0335 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 18s 293us/step - loss: 0.0320 - acc: 0.9896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82928e05f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "JmEIZAbgVTOn",
        "colab_type": "code",
        "outputId": "f7569912-d5ef-407c-cffa-7dcd23db0596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        " preds = pmodel.evaluate(x_test,y_testf)\n",
        "### END CODE HERE ###\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(round(preds[1]*100,3)) + \" %\")\n",
        "del pmodel,wep, wprunedfinal, we, wo\n",
        "print(\"deleted\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 151us/step\n",
            "\n",
            "Loss = 0.033696885677054526\n",
            "Test Accuracy = 98.896 %\n",
            "deleted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4VRVoTc9pwK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def prunen2(list1, p): # list1 = 2D numpy array of weight matrix and p = percent pruning\n",
        "  a = list1.shape[1]\n",
        "  N = a*(100-p)/100\n",
        "  N = int(round(N)) #no. of weights to keep after pruning\n",
        "    \n",
        "  t = np.linalg.norm(list1, axis = 0, keepdims = False) #finding l2 norm of the list1 column wise (returns an 1D array)\n",
        "  t1 = t #copy of t\n",
        "  t2 = np.sort(t)[::-1] #sort t in decending order\n",
        "  thr = t2[N-1]#find last element of t which is at the Nth place because index starts from 0; this is our threshold\n",
        " \n",
        "  for k in range(len(t1)):\n",
        "    if t1[k]> thr:\n",
        "      t1[k] = 1;\n",
        "    else:\n",
        "      t1[k] = 0; #change t1 to a 1D array of 1 and 0 if their l2 norm is greater than threshold\n",
        "  pruned = list1*t1 #broadcast to set the weights of entire columns of list1 to 1 or 0 based on t1\n",
        "  return pruned,t1 \n",
        "w = DLModel.get_weights()\n",
        "wen = []\n",
        "won = []\n",
        "wenp = []\n",
        "wonp = []\n",
        "for i in range(len(w)):\n",
        "  if i%2==0:\n",
        "    wen.append(w[i])\n",
        "  else:\n",
        "    won.append(w[i])# seperate even and odd index weght matrices.\n",
        "    \n",
        "for z in range(len(w)):\n",
        "  if z%2==0 and z!=len(w):\n",
        "    pr, index = prunen2(w[z],99) #prune\n",
        "    prr = np.reshape(pr,w[z].shape)#reshape\n",
        "    wenp.append(prr)\n",
        "    wot = w[z+1]*index #the odd 1D weights are also set to 1 or 0 based on t1 from the function above\n",
        "    wonp.append(wot)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQvgX0EMYv9E",
        "colab_type": "code",
        "outputId": "fe418583-bf9a-48de-b014-fe464f4e2849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "wprunedfinaln = []\n",
        "for i in range(5):\n",
        "  wprunedfinaln.append(wenp[i])\n",
        "  wprunedfinaln.append(wonp[i]) #append the pruned node weight matrix\n",
        "pnmodel = DLModel\n",
        "pnmodel.set_weights(wprunedfinaln) #set weights\n",
        "preds = pnmodel.evaluate(x_test,y_testf)\n",
        "### END CODE HERE ###\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(round(preds[1]*100,3)) + \" %\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 125us/step\n",
            "\n",
            "Loss = 0.678001306438446\n",
            "Test Accuracy = 73.966 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lDBsi6orZhWZ",
        "colab_type": "code",
        "outputId": "12bd5629-84c2-44ae-b486-0c9f25e5ef22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "pnmodel.fit(x = x_train,y = y_trainf, epochs = 4, batch_size = 64)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 0.0716 - acc: 0.9757\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0431 - acc: 0.9859\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 0.0394 - acc: 0.9872\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 0.0374 - acc: 0.9878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f829290a390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "metadata": {
        "id": "L6yO3u_tewKn",
        "colab_type": "code",
        "outputId": "b51f108c-8e2a-497b-9a36-40f8739279c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "preds = pnmodel.evaluate(x_test,y_testf)\n",
        "### END CODE HERE ###\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(round(preds[1]*100,3)) + \" %\")\n",
        "del pnmodel, wprunedfinaln, wen, won, wenp,wonp\n",
        "print(\"deleted\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 144us/step\n",
            "\n",
            "Loss = 0.03676158659607172\n",
            "Test Accuracy = 98.779 %\n",
            "deleted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wqCN-9-ZGWju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}